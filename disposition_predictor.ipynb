{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cc (type), 17353 (act), 865403 (section)\n",
    "case_type = \"cc\"\n",
    "act = 17353\n",
    "section = 865403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/advin4603/PrecogRecruitmentTask/env/lib/python3.10/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 42935 instead\n",
      "  warnings.warn(\n",
      "2023-01-20 13:08:23,704 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-g7srprxg', purging\n",
      "2023-01-20 13:08:23,705 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-fl6mt3ze', purging\n",
      "2023-01-20 13:08:23,705 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-hxmf5i87', purging\n",
      "2023-01-20 13:08:23,705 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-blqwn9yw', purging\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Client: 'tcp://127.0.0.1:32825' processes=4 threads=8, memory=15.52 GiB>",
      "text/html": "<div>\n    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n    <div style=\"margin-left: 48px;\">\n        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-6ac6d23c-9895-11ed-978f-7bf2fbe0ee0f</p>\n        <table style=\"width: 100%; text-align: left;\">\n\n        <tr>\n        \n            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n        \n        </tr>\n\n        \n            <tr>\n                <td style=\"text-align: left;\">\n                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:42935/status\" target=\"_blank\">http://127.0.0.1:42935/status</a>\n                </td>\n                <td style=\"text-align: left;\"></td>\n            </tr>\n        \n\n        </table>\n\n        \n\n        \n            <details>\n            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n    </div>\n    <div style=\"margin-left: 48px;\">\n        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">87290cb4</p>\n        <table style=\"width: 100%; text-align: left;\">\n            <tr>\n                <td style=\"text-align: left;\">\n                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:42935/status\" target=\"_blank\">http://127.0.0.1:42935/status</a>\n                </td>\n                <td style=\"text-align: left;\">\n                    <strong>Workers:</strong> 4\n                </td>\n            </tr>\n            <tr>\n                <td style=\"text-align: left;\">\n                    <strong>Total threads:</strong> 8\n                </td>\n                <td style=\"text-align: left;\">\n                    <strong>Total memory:</strong> 15.52 GiB\n                </td>\n            </tr>\n            \n            <tr>\n    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n</tr>\n\n            \n        </table>\n\n        <details>\n            <summary style=\"margin-bottom: 20px;\">\n                <h3 style=\"display: inline;\">Scheduler Info</h3>\n            </summary>\n\n            <div style=\"\">\n    <div>\n        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n        <div style=\"margin-left: 48px;\">\n            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-794bed4e-4454-44dd-b76c-9f862dfab671</p>\n            <table style=\"width: 100%; text-align: left;\">\n                <tr>\n                    <td style=\"text-align: left;\">\n                        <strong>Comm:</strong> tcp://127.0.0.1:32825\n                    </td>\n                    <td style=\"text-align: left;\">\n                        <strong>Workers:</strong> 4\n                    </td>\n                </tr>\n                <tr>\n                    <td style=\"text-align: left;\">\n                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:42935/status\" target=\"_blank\">http://127.0.0.1:42935/status</a>\n                    </td>\n                    <td style=\"text-align: left;\">\n                        <strong>Total threads:</strong> 8\n                    </td>\n                </tr>\n                <tr>\n                    <td style=\"text-align: left;\">\n                        <strong>Started:</strong> Just now\n                    </td>\n                    <td style=\"text-align: left;\">\n                        <strong>Total memory:</strong> 15.52 GiB\n                    </td>\n                </tr>\n            </table>\n        </div>\n    </div>\n\n    <details style=\"margin-left: 48px;\">\n        <summary style=\"margin-bottom: 20px;\">\n            <h3 style=\"display: inline;\">Workers</h3>\n        </summary>\n\n        \n        <div style=\"margin-bottom: 20px;\">\n            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n            <div style=\"margin-left: 48px;\">\n            <details>\n                <summary>\n                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n                </summary>\n                <table style=\"width: 100%; text-align: left;\">\n                    <tr>\n                        <td style=\"text-align: left;\">\n                            <strong>Comm: </strong> tcp://127.0.0.1:42655\n                        </td>\n                        <td style=\"text-align: left;\">\n                            <strong>Total threads: </strong> 2\n                        </td>\n                    </tr>\n                    <tr>\n                        <td style=\"text-align: left;\">\n                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:37761/status\" target=\"_blank\">http://127.0.0.1:37761/status</a>\n                        </td>\n                        <td style=\"text-align: left;\">\n                            <strong>Memory: </strong> 3.88 GiB\n                        </td>\n                    </tr>\n                    <tr>\n                        <td style=\"text-align: left;\">\n                            <strong>Nanny: </strong> tcp://127.0.0.1:35855\n                        </td>\n                        <td style=\"text-align: left;\"></td>\n                    </tr>\n                    <tr>\n                        <td colspan=\"2\" style=\"text-align: left;\">\n                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-6ytquluv\n                        </td>\n                    </tr>\n\n                    \n\n                    \n\n                </table>\n            </details>\n            </div>\n        </div>\n        \n        <div style=\"margin-bottom: 20px;\">\n            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n            <div style=\"margin-left: 48px;\">\n            <details>\n                <summary>\n                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n                </summary>\n                <table style=\"width: 100%; text-align: left;\">\n                    <tr>\n                        <td style=\"text-align: left;\">\n                            <strong>Comm: </strong> tcp://127.0.0.1:42231\n                        </td>\n                        <td style=\"text-align: left;\">\n                            <strong>Total threads: </strong> 2\n                        </td>\n                    </tr>\n                    <tr>\n                        <td style=\"text-align: left;\">\n                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:43597/status\" target=\"_blank\">http://127.0.0.1:43597/status</a>\n                        </td>\n                        <td style=\"text-align: left;\">\n                            <strong>Memory: </strong> 3.88 GiB\n                        </td>\n                    </tr>\n                    <tr>\n                        <td style=\"text-align: left;\">\n                            <strong>Nanny: </strong> tcp://127.0.0.1:36241\n                        </td>\n                        <td style=\"text-align: left;\"></td>\n                    </tr>\n                    <tr>\n                        <td colspan=\"2\" style=\"text-align: left;\">\n                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-94k9hcrx\n                        </td>\n                    </tr>\n\n                    \n\n                    \n\n                </table>\n            </details>\n            </div>\n        </div>\n        \n        <div style=\"margin-bottom: 20px;\">\n            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n            <div style=\"margin-left: 48px;\">\n            <details>\n                <summary>\n                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 2</h4>\n                </summary>\n                <table style=\"width: 100%; text-align: left;\">\n                    <tr>\n                        <td style=\"text-align: left;\">\n                            <strong>Comm: </strong> tcp://127.0.0.1:42075\n                        </td>\n                        <td style=\"text-align: left;\">\n                            <strong>Total threads: </strong> 2\n                        </td>\n                    </tr>\n                    <tr>\n                        <td style=\"text-align: left;\">\n                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:32791/status\" target=\"_blank\">http://127.0.0.1:32791/status</a>\n                        </td>\n                        <td style=\"text-align: left;\">\n                            <strong>Memory: </strong> 3.88 GiB\n                        </td>\n                    </tr>\n                    <tr>\n                        <td style=\"text-align: left;\">\n                            <strong>Nanny: </strong> tcp://127.0.0.1:39191\n                        </td>\n                        <td style=\"text-align: left;\"></td>\n                    </tr>\n                    <tr>\n                        <td colspan=\"2\" style=\"text-align: left;\">\n                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-lfqtfy6j\n                        </td>\n                    </tr>\n\n                    \n\n                    \n\n                </table>\n            </details>\n            </div>\n        </div>\n        \n        <div style=\"margin-bottom: 20px;\">\n            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n            <div style=\"margin-left: 48px;\">\n            <details>\n                <summary>\n                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 3</h4>\n                </summary>\n                <table style=\"width: 100%; text-align: left;\">\n                    <tr>\n                        <td style=\"text-align: left;\">\n                            <strong>Comm: </strong> tcp://127.0.0.1:35905\n                        </td>\n                        <td style=\"text-align: left;\">\n                            <strong>Total threads: </strong> 2\n                        </td>\n                    </tr>\n                    <tr>\n                        <td style=\"text-align: left;\">\n                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:34015/status\" target=\"_blank\">http://127.0.0.1:34015/status</a>\n                        </td>\n                        <td style=\"text-align: left;\">\n                            <strong>Memory: </strong> 3.88 GiB\n                        </td>\n                    </tr>\n                    <tr>\n                        <td style=\"text-align: left;\">\n                            <strong>Nanny: </strong> tcp://127.0.0.1:38133\n                        </td>\n                        <td style=\"text-align: left;\"></td>\n                    </tr>\n                    <tr>\n                        <td colspan=\"2\" style=\"text-align: left;\">\n                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-isfz_jla\n                        </td>\n                    </tr>\n\n                    \n\n                    \n\n                </table>\n            </details>\n            </div>\n        </div>\n        \n\n    </details>\n</div>\n\n        </details>\n    </div>\n</div>\n            </details>\n        \n\n    </div>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "client"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                   ddl_case_id  duration  year  state_code  dist_code  \\\n1140  17-18-03-205900014452015       495  2015          17         18   \n2069  17-11-02-205900169332010      1319  2010          17         11   \n1568  29-04-07-202101003982011       142  2011          29          4   \n1207  02-21-04-202102006132013       359  2013           2         21   \n996   04-02-05-202905014642012       106  2012           4          2   \n...                        ...       ...   ...         ...        ...   \n1036  04-05-10-202900010622014       142  2014           4          5   \n490   17-22-05-205900006002018       359  2018          17         22   \n490   29-07-10-202100002162018       596  2017          29          7   \n1538  29-02-03-202108006522013        86  2013          29          2   \n945   02-02-05-202101004992018         2  2018           2          2   \n\n      court_no female_defendant female_petitioner female_adv_def  \\\n1140         3           0 male     -9998 unclear              0   \n2069         2           0 male     -9998 unclear          -9999   \n1568         7         1 female          1 female              0   \n1207         4           0 male     -9998 unclear          -9999   \n996          5           0 male     -9998 unclear          -9999   \n...        ...              ...               ...            ...   \n1036        10           0 male     -9998 unclear          -9999   \n490          5           0 male     -9998 unclear          -9999   \n490         10           0 male          1 female          -9999   \n1538         3           0 male     -9998 unclear          -9999   \n945          5           0 male            0 male          -9999   \n\n     female_adv_pet             disp_name_s  fd  fp  fad  fap  dp  \n1140          -9998               judgement   2   0    2    0   8  \n2069          -9999               judgement   2   0    1    1   8  \n1568              0  referred to lok adalat   3   2    2    2  10  \n1207              0  referred to lok adalat   2   0    1    2  10  \n996           -9999                    fine   2   0    1    1  16  \n...             ...                     ...  ..  ..  ...  ...  ..  \n1036          -9999               convicted   2   0    1    1   5  \n490           -9998               judgement   2   0    1    0   8  \n490           -9999              confession   2   2    1    1   4  \n1538          -9999             transferred   2   0    1    1  11  \n945           -9999  referred to lok adalat   2   1    1    1  10  \n\n[166653 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ddl_case_id</th>\n      <th>duration</th>\n      <th>year</th>\n      <th>state_code</th>\n      <th>dist_code</th>\n      <th>court_no</th>\n      <th>female_defendant</th>\n      <th>female_petitioner</th>\n      <th>female_adv_def</th>\n      <th>female_adv_pet</th>\n      <th>disp_name_s</th>\n      <th>fd</th>\n      <th>fp</th>\n      <th>fad</th>\n      <th>fap</th>\n      <th>dp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1140</th>\n      <td>17-18-03-205900014452015</td>\n      <td>495</td>\n      <td>2015</td>\n      <td>17</td>\n      <td>18</td>\n      <td>3</td>\n      <td>0 male</td>\n      <td>-9998 unclear</td>\n      <td>0</td>\n      <td>-9998</td>\n      <td>judgement</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2069</th>\n      <td>17-11-02-205900169332010</td>\n      <td>1319</td>\n      <td>2010</td>\n      <td>17</td>\n      <td>11</td>\n      <td>2</td>\n      <td>0 male</td>\n      <td>-9998 unclear</td>\n      <td>-9999</td>\n      <td>-9999</td>\n      <td>judgement</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1568</th>\n      <td>29-04-07-202101003982011</td>\n      <td>142</td>\n      <td>2011</td>\n      <td>29</td>\n      <td>4</td>\n      <td>7</td>\n      <td>1 female</td>\n      <td>1 female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>referred to lok adalat</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1207</th>\n      <td>02-21-04-202102006132013</td>\n      <td>359</td>\n      <td>2013</td>\n      <td>2</td>\n      <td>21</td>\n      <td>4</td>\n      <td>0 male</td>\n      <td>-9998 unclear</td>\n      <td>-9999</td>\n      <td>0</td>\n      <td>referred to lok adalat</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>04-02-05-202905014642012</td>\n      <td>106</td>\n      <td>2012</td>\n      <td>4</td>\n      <td>2</td>\n      <td>5</td>\n      <td>0 male</td>\n      <td>-9998 unclear</td>\n      <td>-9999</td>\n      <td>-9999</td>\n      <td>fine</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1036</th>\n      <td>04-05-10-202900010622014</td>\n      <td>142</td>\n      <td>2014</td>\n      <td>4</td>\n      <td>5</td>\n      <td>10</td>\n      <td>0 male</td>\n      <td>-9998 unclear</td>\n      <td>-9999</td>\n      <td>-9999</td>\n      <td>convicted</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>490</th>\n      <td>17-22-05-205900006002018</td>\n      <td>359</td>\n      <td>2018</td>\n      <td>17</td>\n      <td>22</td>\n      <td>5</td>\n      <td>0 male</td>\n      <td>-9998 unclear</td>\n      <td>-9999</td>\n      <td>-9998</td>\n      <td>judgement</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>490</th>\n      <td>29-07-10-202100002162018</td>\n      <td>596</td>\n      <td>2017</td>\n      <td>29</td>\n      <td>7</td>\n      <td>10</td>\n      <td>0 male</td>\n      <td>1 female</td>\n      <td>-9999</td>\n      <td>-9999</td>\n      <td>confession</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1538</th>\n      <td>29-02-03-202108006522013</td>\n      <td>86</td>\n      <td>2013</td>\n      <td>29</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0 male</td>\n      <td>-9998 unclear</td>\n      <td>-9999</td>\n      <td>-9999</td>\n      <td>transferred</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>945</th>\n      <td>02-02-05-202101004992018</td>\n      <td>2</td>\n      <td>2018</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>0 male</td>\n      <td>0 male</td>\n      <td>-9999</td>\n      <td>-9999</td>\n      <td>referred to lok adalat</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n<p>166653 rows Ã— 16 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = dd.read_parquet(\"Parquet/features_classes/\")\n",
    "fc = fc.compute()\n",
    "fc = fc.sample(frac=1)\n",
    "fc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "class DispositionDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame):\n",
    "        self.duration = dataframe[\"duration\"]\n",
    "        self.year = dataframe[\"year\"].iloc\n",
    "        self.state_code = dataframe[\"state_code\"].iloc\n",
    "        self.dist_code = dataframe[\"dist_code\"].iloc\n",
    "        self.court_no = dataframe[\"court_no\"].iloc\n",
    "        self.female_def = dataframe[\"fd\"].iloc\n",
    "        self.female_pet = dataframe[\"fp\"].iloc\n",
    "        self.female_adv_def = dataframe[\"fad\"].iloc\n",
    "        self.female_adv_pet = dataframe[\"fap\"].iloc\n",
    "        self.disposition = dataframe[\"dp\"].iloc\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.duration)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        duration = self.duration.iloc[idx]\n",
    "        year = self.year[idx]\n",
    "        state_code = self.state_code[idx]\n",
    "        dist_code = self.dist_code[idx]\n",
    "        court_no = self.court_no[idx]\n",
    "        female_def = self.female_def[idx]\n",
    "        female_pet = self.female_pet[idx]\n",
    "        female_adv_def = self.female_adv_def[idx]\n",
    "        female_adv_pet = self.female_adv_pet[idx]\n",
    "        disposition = self.disposition[idx]\n",
    "\n",
    "        return torch.Tensor((duration / 5000, year - 2010, state_code, dist_code, court_no, female_def, female_pet,\n",
    "                             female_adv_def, female_adv_pet)), int(disposition)\n",
    "\n",
    "\n",
    "train_data = DispositionDataset(fc[:-20000])\n",
    "test_data = DispositionDataset(fc[-20000:])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# learning_rate = .001\n",
    "# weight_decay = 1e-2\n",
    "batch_size = 100\n",
    "epochs = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import optuna\n",
    "\n",
    "\n",
    "class DispositionPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DispositionPredictor, self).__init__()\n",
    "        n_layers = 1\n",
    "        layers = []\n",
    "        in_features = 9\n",
    "        for i in range(n_layers):\n",
    "            out_features = 18\n",
    "            layers.append(nn.Linear(in_features, out_features))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_features = out_features\n",
    "        layers.append(nn.Linear(in_features, 34))\n",
    "        self.linear_relu_stack = nn.Sequential(*layers)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return self.softmax(logits)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(torch.Tensor(X))\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-01-20 13:20:55,420]\u001B[0m A new study created in memory with name: no-name-7ffd5057-85cc-495d-ba87-bab3a83c136c\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] loss: 3.517288  [    0/146653]\n",
      "[Training] loss: 3.158055  [10000/146653]\n",
      "[Training] loss: 3.201867  [20000/146653]\n",
      "[Training] loss: 3.213402  [30000/146653]\n",
      "[Training] loss: 3.062239  [40000/146653]\n",
      "[Training] loss: 3.153908  [50000/146653]\n",
      "[Training] loss: 3.214943  [60000/146653]\n",
      "[Training] loss: 3.138347  [70000/146653]\n",
      "[Training] loss: 3.067544  [80000/146653]\n",
      "[Training] loss: 3.046072  [90000/146653]\n",
      "[Training] loss: 3.022060  [100000/146653]\n",
      "[Training] loss: 3.183343  [110000/146653]\n",
      "[Training] loss: 3.117736  [120000/146653]\n",
      "[Training] loss: 3.090921  [130000/146653]\n",
      "[Training] loss: 3.156540  [140000/146653]\n",
      "0:[Test] Error: \n",
      " Accuracy: 48.1%, Avg loss: 3.096753 \n",
      "\n",
      "[Training] loss: 3.073262  [    0/146653]\n",
      "[Training] loss: 3.095058  [10000/146653]\n",
      "[Training] loss: 3.156502  [20000/146653]\n",
      "[Training] loss: 3.173889  [30000/146653]\n",
      "[Training] loss: 3.006078  [40000/146653]\n",
      "[Training] loss: 3.079429  [50000/146653]\n",
      "[Training] loss: 3.135770  [60000/146653]\n",
      "[Training] loss: 3.020242  [70000/146653]\n",
      "[Training] loss: 3.065017  [80000/146653]\n",
      "[Training] loss: 3.062856  [90000/146653]\n",
      "[Training] loss: 3.032160  [100000/146653]\n",
      "[Training] loss: 3.144202  [110000/146653]\n",
      "[Training] loss: 3.125917  [120000/146653]\n",
      "[Training] loss: 3.101415  [130000/146653]\n",
      "[Training] loss: 3.154763  [140000/146653]\n",
      "1:[Test] Error: \n",
      " Accuracy: 48.0%, Avg loss: 3.096094 \n",
      "\n",
      "[Training] loss: 3.069192  [    0/146653]\n",
      "[Training] loss: 3.083928  [10000/146653]\n",
      "[Training] loss: 3.155627  [20000/146653]\n",
      "[Training] loss: 3.157312  [30000/146653]\n",
      "[Training] loss: 3.006034  [40000/146653]\n",
      "[Training] loss: 3.087379  [50000/146653]\n",
      "[Training] loss: 3.137259  [60000/146653]\n",
      "[Training] loss: 3.024309  [70000/146653]\n",
      "[Training] loss: 3.072904  [80000/146653]\n",
      "[Training] loss: 3.065565  [90000/146653]\n",
      "[Training] loss: 3.032972  [100000/146653]\n",
      "[Training] loss: 3.142402  [110000/146653]\n",
      "[Training] loss: 3.120744  [120000/146653]\n",
      "[Training] loss: 3.103317  [130000/146653]\n",
      "[Training] loss: 3.152885  [140000/146653]\n",
      "2:[Test] Error: \n",
      " Accuracy: 48.0%, Avg loss: 3.096100 \n",
      "\n",
      "[Training] loss: 3.060640  [    0/146653]\n",
      "[Training] loss: 3.055034  [10000/146653]\n",
      "[Training] loss: 3.155732  [20000/146653]\n",
      "[Training] loss: 3.167019  [30000/146653]\n",
      "[Training] loss: 3.001740  [40000/146653]\n",
      "[Training] loss: 3.083836  [50000/146653]\n",
      "[Training] loss: 3.137234  [60000/146653]\n",
      "[Training] loss: 3.020390  [70000/146653]\n",
      "[Training] loss: 3.064349  [80000/146653]\n",
      "[Training] loss: 3.050199  [90000/146653]\n",
      "[Training] loss: 3.010753  [100000/146653]\n",
      "[Training] loss: 3.158991  [110000/146653]\n",
      "[Training] loss: 3.122893  [120000/146653]\n",
      "[Training] loss: 3.103102  [130000/146653]\n",
      "[Training] loss: 3.149056  [140000/146653]\n",
      "3:[Test] Error: \n",
      " Accuracy: 48.0%, Avg loss: 3.097031 \n",
      "\n",
      "[Training] loss: 3.061194  [    0/146653]\n",
      "[Training] loss: 3.086974  [10000/146653]\n",
      "[Training] loss: 3.156418  [20000/146653]\n",
      "[Training] loss: 3.139264  [30000/146653]\n",
      "[Training] loss: 3.007754  [40000/146653]\n",
      "[Training] loss: 3.076552  [50000/146653]\n",
      "[Training] loss: 3.136403  [60000/146653]\n",
      "[Training] loss: 3.020331  [70000/146653]\n",
      "[Training] loss: 3.058795  [80000/146653]\n",
      "[Training] loss: 3.052796  [90000/146653]\n",
      "[Training] loss: 3.014881  [100000/146653]\n",
      "[Training] loss: 3.139019  [110000/146653]\n",
      "[Training] loss: 3.123968  [120000/146653]\n",
      "[Training] loss: 3.103196  [130000/146653]\n",
      "[Training] loss: 3.153923  [140000/146653]\n",
      "4:[Test] Error: \n",
      " Accuracy: 48.1%, Avg loss: 3.095727 \n",
      "\n",
      "[Training] loss: 3.059214  [    0/146653]\n",
      "[Training] loss: 3.080715  [10000/146653]\n",
      "[Training] loss: 3.155915  [20000/146653]\n",
      "[Training] loss: 3.145020  [30000/146653]\n",
      "[Training] loss: 3.008615  [40000/146653]\n",
      "[Training] loss: 3.080586  [50000/146653]\n",
      "[Training] loss: 3.136685  [60000/146653]\n",
      "[Training] loss: 3.022150  [70000/146653]\n",
      "[Training] loss: 3.068557  [80000/146653]\n",
      "[Training] loss: 3.050027  [90000/146653]\n",
      "[Training] loss: 3.025093  [100000/146653]\n",
      "[Training] loss: 3.143714  [110000/146653]\n",
      "[Training] loss: 3.121993  [120000/146653]\n",
      "[Training] loss: 3.102083  [130000/146653]\n",
      "[Training] loss: 3.150340  [140000/146653]\n",
      "5:[Test] Error: \n",
      " Accuracy: 48.0%, Avg loss: 3.097004 \n",
      "\n",
      "[Training] loss: 3.060158  [    0/146653]\n",
      "[Training] loss: 3.053175  [10000/146653]\n",
      "[Training] loss: 3.156090  [20000/146653]\n",
      "[Training] loss: 3.146466  [30000/146653]\n",
      "[Training] loss: 3.008192  [40000/146653]\n",
      "[Training] loss: 3.080703  [50000/146653]\n",
      "[Training] loss: 3.137782  [60000/146653]\n",
      "[Training] loss: 3.021041  [70000/146653]\n",
      "[Training] loss: 3.070860  [80000/146653]\n",
      "[Training] loss: 3.043937  [90000/146653]\n",
      "[Training] loss: 3.023576  [100000/146653]\n",
      "[Training] loss: 3.143881  [110000/146653]\n",
      "[Training] loss: 3.121877  [120000/146653]\n",
      "[Training] loss: 3.102147  [130000/146653]\n",
      "[Training] loss: 3.152823  [140000/146653]\n",
      "6:[Test] Error: \n",
      " Accuracy: 48.1%, Avg loss: 3.096377 \n",
      "\n",
      "[Training] loss: 3.059184  [    0/146653]\n",
      "[Training] loss: 3.086884  [10000/146653]\n",
      "[Training] loss: 3.155950  [20000/146653]\n",
      "[Training] loss: 3.150639  [30000/146653]\n",
      "[Training] loss: 3.007178  [40000/146653]\n",
      "[Training] loss: 3.079899  [50000/146653]\n",
      "[Training] loss: 3.137087  [60000/146653]\n",
      "[Training] loss: 3.023313  [70000/146653]\n",
      "[Training] loss: 3.069046  [80000/146653]\n",
      "[Training] loss: 3.044712  [90000/146653]\n",
      "[Training] loss: 3.026293  [100000/146653]\n",
      "[Training] loss: 3.141694  [110000/146653]\n",
      "[Training] loss: 3.131397  [120000/146653]\n",
      "[Training] loss: 3.103302  [130000/146653]\n",
      "[Training] loss: 3.153387  [140000/146653]\n",
      "7:[Test] Error: \n",
      " Accuracy: 48.1%, Avg loss: 3.095664 \n",
      "\n",
      "[Training] loss: 3.062980  [    0/146653]\n",
      "[Training] loss: 3.079061  [10000/146653]\n",
      "[Training] loss: 3.155942  [20000/146653]\n",
      "[Training] loss: 3.154605  [30000/146653]\n",
      "[Training] loss: 3.006735  [40000/146653]\n",
      "[Training] loss: 3.078683  [50000/146653]\n",
      "[Training] loss: 3.137354  [60000/146653]\n",
      "[Training] loss: 3.018149  [70000/146653]\n",
      "[Training] loss: 3.070913  [80000/146653]\n",
      "[Training] loss: 3.043114  [90000/146653]\n",
      "[Training] loss: 3.016651  [100000/146653]\n",
      "[Training] loss: 3.143407  [110000/146653]\n",
      "[Training] loss: 3.133615  [120000/146653]\n",
      "[Training] loss: 3.102549  [130000/146653]\n",
      "[Training] loss: 3.150365  [140000/146653]\n",
      "8:[Test] Error: \n",
      " Accuracy: 48.1%, Avg loss: 3.095705 \n",
      "\n",
      "[Training] loss: 3.061725  [    0/146653]\n",
      "[Training] loss: 3.082068  [10000/146653]\n",
      "[Training] loss: 3.155919  [20000/146653]\n",
      "[Training] loss: 3.147453  [30000/146653]\n",
      "[Training] loss: 3.006369  [40000/146653]\n",
      "[Training] loss: 3.078657  [50000/146653]\n",
      "[Training] loss: 3.137959  [60000/146653]\n",
      "[Training] loss: 3.022746  [70000/146653]\n",
      "[Training] loss: 3.069555  [80000/146653]\n",
      "[Training] loss: 3.043794  [90000/146653]\n",
      "[Training] loss: 3.016330  [100000/146653]\n",
      "[Training] loss: 3.140886  [110000/146653]\n",
      "[Training] loss: 3.120830  [120000/146653]\n",
      "[Training] loss: 3.102536  [130000/146653]\n",
      "[Training] loss: 3.149288  [140000/146653]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-01-20 13:23:01,528]\u001B[0m Trial 0 finished with value: 0.48065 and parameters: {}. Best is trial 0 with value: 0.48065.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:[Test] Error: \n",
      " Accuracy: 48.1%, Avg loss: 3.095501 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(param, model, trial, train_dataloader, test_dataloader):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(torch.optim, param['optimizer'])(model.parameters(), lr=param['learning_rate'], weight_decay=param['weight_decay'])\n",
    "    size = len(train_dataloader.dataset)\n",
    "    test_size = len(test_dataloader.dataset)\n",
    "    for epoch_num in range(epochs):\n",
    "        for batch_num, (X, y) in enumerate(train_dataloader):\n",
    "            # Compute prediction and loss\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(torch.Tensor(X))\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_num % 100 == 0:\n",
    "                loss, current = loss.item(), batch_num * len(X)\n",
    "                print(f\"[Training] loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "        num_batches = len(test_dataloader)\n",
    "        test_loss, correct = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_dataloader:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                pred = model(X)\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "                correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        test_loss /= num_batches\n",
    "        correct /= test_size\n",
    "        print(f\"{epoch_num}:[Test] Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "        trial.report(correct, epoch_num)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return correct\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'learning_rate': 0.014,\n",
    "        # 'weight_decay': 0.0005310881230135281,\n",
    "        'weight_decay': 0.0003,\n",
    "        # 'weight_decay': 0,\n",
    "        'optimizer': \"Adam\"\n",
    "    }\n",
    "    model = DispositionPredictor().to(device)\n",
    "    accuracy = train_and_evaluate(params, model, trial, train_dataloader, test_dataloader)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\",\n",
    "                            sampler=optuna.samplers.TPESampler(),\n",
    "                            pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "best_trial = study.best_trial\n",
    "\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"{}: {}\".format(key, value))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
